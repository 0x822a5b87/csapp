# 虚拟内存

## 9.1 物理和虚拟寻址

1. 早期的 PC 使用物理寻址直接读取内存
2. 现代 PC 不直接访问内存，而是通过将虚拟地址传给 MMU 来访问实际物理内存；

## 9.3 虚拟内存作为缓存工具

1. 虚拟内存会存储在磁盘和物理内存两个位置，并且都是连续的空间；
2. 其中一部分数据会被缓存到物理内存中，而另外一部分会存放在磁盘中
3. 虚拟内存中的每一页称之为 `虚拟页`，物理内存被分割为 `物理页（或者页帧）`，

### 9.3.1 DRAM 缓存的组织结构

1. 我们用 SRAM 表示L1等高速缓存，DRAM 表示虚拟内存系统的缓存（也就是我们的物理内存）
2. 由于不命中缓存的惩罚太过严重，所以虚拟页往往设置得很大，并且需要很复杂的替换算法

### 9.3.2 页表

1. 页表就是一个 PTE（Page Table Entry）数组，每一个 PTE 保存了虚拟内存中的 **某一个 `虚拟页` 的信息**。操作系统，MMU 和页表共同管理虚拟内存。


```cpp
struct
{
    // 是否有效 true or false
    short effective;
    // 物理页号或者磁盘地址
    long  pageIndexOrDiskAddr
} pte;
``` 

```cpp
// 当 CPU 通过虚拟内存发动一次实际内存访问的伪代码如下
pte = mmu.get_pte();
if (pte.effective)
{
	access_memory(pte.pageIndexOrDiskAddr);
}
else
{
	if (pte.pageIndexOrDiskAddr)
	{
		access_disk(pte.pageIndexOrDiskAddr);
	}
	else
	{
		// 该虚拟页尚未加载
	}
}
```

### 9.3.4 缺页

1. 当 CPU 访问的虚拟内存没有缓存到 DRAM 中时，会产生一个 `缺页异常`
2. 当 CPU 在页表中查询虚拟地址时，如果 pte.effective 无效则发生缺页异常，此时会将磁盘上的对应页帧加载到 DRAM。那个被替换的 DRAM 中的页帧如果有修改，那么它必须被写入磁盘。

## 9.4 虚拟内存作为内存管理的工具

1. 操作系统为每个进程提供了一个独立的页表
2. 操作系统可以将不同进程中的适当虚拟页面映射到相同的物理页面，从而安排多个进程共享代码和数据

## 9.5 虚拟内存作为内存保护的工具

1. 之前提到过，PTE 上可以通过页面是否缓存来决定读取内存还是磁盘。此外， PTE 还可以增加标志符 `SUP`,`READ`,`WRITE` 来标志权限问题
2. 如果一条指令违反了这些许可条件，例如在用户态访问 `SUP` 内存，写没有 `WRITE` 权限的内存都会引发一个 `segmentation fault`

## 9.6 地址翻译

1. 虚拟地址与实际的物理地址不需要一直。例如，我们的虚拟地址可能是 64mb，但是我们的物理地址却只有 32mb；
2. 几个关键概念
    2.1 VPN         虚拟页号
    2.2 VPO         虚拟页偏移量
    2.3 PPN         物理页号
    2.4 PPO         物理页偏移量
    2.4 PageSize    页大小
3. 假设我们的虚拟内存为 32 位，我们的物理地址为 24 位，我们的页大小为 1kb
    3.1 由于页大小为 1kb，所以需要用低 10 位来表示 VPO
    3.2 PPO 和 VPO 一致
    3.3 虚拟内存的高 22 位可以用来表示 VPN
    3.4 物理内存的高 14 位可以用来表示 PPN
    3.5 这就是虚拟内存不需要和物理内存大小一样的原因
    

### 9.6.2 利用 TLB 加速地址翻译

1. TLB 就是用来查找 VPN 对应的那页的 PPN 信息。因为如果不是用 TLB，那么需要先访问页表查询页是否可用，就会有两次内存访问。
2. TLB 的结构包含：
	2.1 标记位	用于匹配
	2.2 PPN		物理页地址
	2.3 有效位	DRAM 是否有效
3. 和VPN，VPO这种两段确定地址的不一样，TLB 需要三段才能确定具体的地址：
	3.1 低位用于确定条目
	3.2 中位用于确定组
	3.3 高位用于和条目中的标记位进行匹配
4. 使用 VPN 地址查询 TLB：假设我们的 TLB 包含了 4 组，每组包含 4 个条目
	3.1 低 4 位用于确定组合条目
	3.2 `0-1` 位用于确定 TLB 组的条目
	3.3 `2-N` 位用于确定 TLB 组

### 9.6.3 多级页表

1. 压缩页表的常用方法是使用层次结构的页
2. 假设我们的一级页表是一个长度为 1024 的数组，数组的每个元素都指向一个二级页表。二级页表指向的是实际的 PTE。
	2.1 假设 PageSize = 4kb，那么一个二级页表可以表示 4mb 的虚拟内存空间，一级页表可以表示 4GB 的虚拟内存空间；
	2.2 如果二级页表中的任意一个 PTE 初始化了，那么它对应的一级页表也必须被初始化
	2.3 对于大部分情况，例如我们 4GB 的虚拟内存，实际只有 768MB 的物理内存来讲，大部分的一级页表实际上是出于未初始化状态。所以可以有效的节省页表所占用的内存。如果我们不使用二级页表，那么我们需要耗费 `4mb` 的页表常驻内存，而二级页表只需要 `1mb` 左右；代价是性能稍低，并且会增加复杂性。
	2.4 只有一级页表才需要常驻内存，二级页表只有那些常用的才需要常驻内存。

### 9.6.4 端到端的地址翻译

>描述一下地址翻译的整个流程

1. CPU 执行地址读取指令
2. MMU 从地址中取出 VPN：虚拟地址低位作为 VPO，高位地址作为 VPN
3. 使用 VPN 地址查询TLB：参考 **9.6.2**
4. 如果 TLB 显示状态有效，那么我们直接从 TLB 中获得 PPN
5. 如果 TLB 显示状态无效，那么我们就需要去从页表中获取指定的 PTE，并得到 PPN
6. 现在我们需要将 PPN 和 VPO 结合起来得到实际的物理地址。根据 PageSize 的大小，我们将物理地址的低 N 位设置为 VPO 并用零补齐高空位。随后将剩余的位设置为 PPN

总结一下就是：

1. 虚拟地址 -> VPN 和 VPO
2. 使用 VPN 通过 TLB 查询 PPN
3. 如果查询失败通过页表查询 PPN
4. 使用 PPN + VPO 得到物理地址
5. 如果出现缺页异常，那么需要在缺页异常的处理程序中从磁盘读取数据并更新 SRAM,DRAM,TLB,页表

## 9.7 案例研究：Intel Core/i7/Linux 内存系统

1. linux 默认使用 4kb 大小的页，可以在 `启动时` 被配置为 4KB 或者 4MB

### 9.7.1 Core i7 地址翻译

1. 一级页表的起始位置是 `进程上下文的一部分`，每次上下文切换时这个值都会被恢复到一个固定的寄存器
2. i7 使用四级页表。对于第一级，第二级，第三级页表，当 P == 1 时，代表这个页表的下级页表包含了一个已分配的页表。并且该 PTE 包含了一个指向下级页表的物理页号
3. 对于第四级页表，当 P == 1 时它指向物理内存中的某一页的基地址
4. 地址解析的时候会包含两个必要程序：根据 VPN 查找 PPN，根据 VPO 来查找 L1 并更新 L1。在 i7 中，这两步是并行的。因为 i7 的 L1 包含了 64 组 8 行的寄存器，每行可以缓存 8 个字节。所以正好需要用 12 位来表示 L1 缓存。这正好和 VPO 的位数一致。

### 9.7.2 linux 虚拟内存系统

1. linux 将一组连续的虚拟页面映射到一组连续的物理页面。
2. linux 将虚拟内存组织成一些区域（或者说段）的集合（例如 .text, .bss）， **每个存在的虚拟页面都保存在某个区域中，而不属于某个区域的虚拟页是不存在的，并且不能被进程引用**
3. 每一个进程都包含了一个 `task_struct` 保存了内核运行该进程所需要的信息，这个结构体包含了一个 `mm_struct` 结构体
4. `mm_struct` 结构体包含了 `pgd` 指向了一级页表的基址。mmap 指向一个 `vm_area_struct` 的数组
5. `vm_area_struct` 中包含了每个 `segment` 的信息。`vm_start` 代表了段的起始地址，`vm_end` 代表了段的结束地址。
6. **每个 `segment` 在内存中不是连续的**。当我们在缺页异常中访问了一个 **不在任何 segment 的地址**，就会产生一个段错误异常

## 9.8 内存映射

1. linux 通过将虚拟内存和磁盘上的一个对象关联起来称之为内存映射；
2. 一旦一个虚拟页面被初始化了，它就在一个由内核维护的交换文件中不停的交换
3. 一个对象可以被映射到虚拟内存中，成为 `共享对象` 或者 `私有对象`
4. `共享对象` 被映射到物理内存中之后，也会在 swap 空间内被替换。各个不同的进程间把自己的虚拟内存的一段连续空间映射到这一块物理空间上
5. `私有对象` 是各个进程之间共享的，但是采用了 `copy-on-write` 技术。所有的数据一开始是完全共享的，但是假设某一个进程去执行了写操作，那么就会把这一段复制到单独的地址空间并修改。同时让虚拟内存指向这个新的地址空间。

## 9.9 动态内存分配

1. 动态内存分配器维护着一个进程的虚拟内存区域，称之为 `堆`
2. 分配器将堆视为一组不同大小的块。一个块要么是已分配的，要么是未分配的；
3. C 可以通过 `malloc`,`free` 等函数来控制堆内存的分配，而 java 之类的高级语言是通过垃圾收集器来实现分配和回收

### 9.9.1 malloc 和 free 函数

1. malloc 函数返回一个指针，指向大小至少为 `size` 字节的内存块。这个块可能会会包含在内存内的数据对象做内存对齐
2. malloc 在错误时返回 NULL
3. `sbrk` 函数通过修改内核的 `brk` 指针来扩展和收缩堆。如果成功则返回 brk 的旧值
	3.1 incr == 0 则返回旧指针地址
	3.2 incr < 0 减少堆大小，并且返回值指向新堆向上 abs(incr) 字节处
	3.3 incr > 0 增加堆大小
4. free 可以释放一个通过 malloc 指向的块，如果这个块不是通过 malloc 来分配的，那么行为是未定义的
5. 通过 <3> 我们可以再回想起之前提到的，我们的虚拟内存空间不需要是连续的。这样我们的 sbrk 函数才可以简单的增加或者减少堆的大小

### 9.9.2 为什么要使用动态内存分配

1. 我们可能直到运行时才知道某些数据结构的大小
2. 普通的变量，在函数退出就消失。但是有些时候我们希望手动控制对象的生命周期

### 9.9.3 分配器的要求和目标

1. 分配器有一个重要的要求是， **它只能操作或者改变空闲块**

### 9.9.4 碎片

1. 我们在分配空间时，为了内存对齐或者其他的原因而多分配的空间。这部分空间称之为 `内部碎片`
2. 当我们空闲内存连在一起，但是却被当做两个独立的内存块，这部分内存就称之为 `外部碎片`

### 9.9.6 隐式空闲链表

1. 我们把一段分配的内存分为三个部分：头部，有效核载，填充
2. 头部自身的大小可能是 4 字节，他表明了整个头部的大小
	2.1 由于使用2字对齐，所以头部的低3位肯定为0，我们可以用低3位来表示这个块是否被分配
	2.2 value_of(head) = sizeof(block) | (allocate ? 0x1 : 0x0);
	2.3 sizeof(block) = sizeof(head) + load(block) + align

### 9.9.10 合并空闲块

1. 当一个内存片段被 free 的时候，如果他的前后有另外一个空闲片段，那么我们必须将他们合并成一个新的，更大的空闲片段；
2. 合并的时机可以是立即合并或者推迟合并。为了简单我们暂时使用立即合并，而快速的分配器会使用推迟合并

### 9.9.11 带边界标记的合并

1. 对于普通的隐式链表结构，我们唯一的选择是搜索整个链表。因为假设我们 free 了一个块，我们根本就无法知道它前面的那个块是已分配还是未分配；
2. 我们可以通过给每一个块增加一个脚标记来解决这个问题。当我们 free 一个块，我们只需要将指针向前移 4 个字就可以知道这个块的大小可以分配情况；
	2.1 这会降低内存的有效核载，假设我们需要频繁的分配那种双字的小内存块，那么我们的这种方式将浪费很多的内存；

### 9.9.12 综合：实现一个简单的分配器

1. 隐式链表：每个列表包含一个 head 和一个 foot，并且 head 和 foot 中包含了块的大小以及分配情况
2. 为了简化我们开发时可能碰到的边界条件，所以我们有两个很简单的优化：增加了 prologue 和 epilogue
	2.1 堆的第一个字是一个占位块，用于与 prologue + epilogue 进行字节对齐
	2.2 prologue 是一个 size == 8 的已分配块，因为 head  和 foot 的大小为 8，这意味着这个块没有有效核载
	2.3 epilogue 是一个 size == 0 的已分配块，当我们碰到一个大小为0的块时，我们就知道达到了堆的结尾
3. 有一个特殊的指针 `static char *heap_listp`  永久的指向 prologue

### 9.9.13 显式空闲链表

1. 隐式空闲链表有个很大的问题在于，当我们需要搜索一个合适的块时最差情况可能是 O(n) 的时间复杂度，n 等于 `链表中块的数量`
2. 我们可以通过将空闲块与分配块独立开来，我们为每个空闲块增加 prev 和 next 指针，那么我们搜索的复杂度就变成了 `链表中空闲块的数量` 相关的时间复杂度

### 9.9.14 分离的空闲链表

1. 分离存储就是维护多个空闲链表，其中每个链表中的块大小相似
2. 每次我们要获取一个块时我们就去搜索对应的空闲链表中是否有对应的块。如果有我们直接使用，如果没有则我们从更大的空闲链表中取出来一块并拆分。如果更大的块中也没有，我们就就必须从系统申请更大的堆内存了；
3. 每次当我们 free 内存的时候，我们就执行合并并将合并后的内存加入到对应的空闲链表中。
4. 伙伴系统：我们将所有的块都拆分为2<sup>k</sup>，当我们分配时就直接使用大于所需 size 的那个块。当没有合适的块时，我们就将一个更大的块拆分成两个更小的块（大小除以2）。坏处是内部碎片会很多，好处是合并和拆分都很快，给定地址和块的大小可以很容易计算出他的伙伴的大小。






























